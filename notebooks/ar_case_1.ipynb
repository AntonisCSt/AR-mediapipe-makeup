{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@alishbakhalid058/virtual-makeup-lipstick-using-python-9abd7c0bd477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Define lip landmarks for the upper and lower lips\n",
    "upper_lip = [61, 185, 40, 39, 37, 0, 267, 269, 270, 408, 415, 272, 271, 268, 12, 38, 41, 42, 191, 78, 76]\n",
    "lower_lip = [61, 146, 91, 181, 84, 17, 314, 405, 320, 307, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "\n",
    "# Function to detect landmarks using MediaPipe\n",
    "def detect_landmarks(src: np.ndarray) -> list | None:\n",
    "    \"\"\"\n",
    "    Detect the landmarks of the face using MediaPipe face mesh.\n",
    "    :param src: Input image (BGR format).\n",
    "    :return: A list of landmarks or None if no landmarks are detected.\n",
    "    \"\"\"\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh()  # Initialize the face mesh detector\n",
    "    #rgb = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)  # Convert BGR image to RGB\n",
    "    results = face_mesh.process(src)  # Process the image to get landmarks\n",
    "\n",
    "    if results.multi_face_landmarks:  # If landmarks are detected\n",
    "        return results.multi_face_landmarks[0].landmark  # Return the first face's landmarks\n",
    "    return None  # Return None if no landmarks are detected\n",
    "\n",
    "# Function to extract and normalize landmarks for lips\n",
    "def landmarks(landmarks: list, height: int, width: int, mask: list | None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract and normalize the lip landmarks for the image.\n",
    "    :param landmarks: List of face landmarks.\n",
    "    :param height: Height of the input image.\n",
    "    :param width: Width of the input image.\n",
    "    :param mask: A list of indices to extract the lip region.\n",
    "    :return: Array of lip landmarks with normalized coordinates.\n",
    "    \"\"\"\n",
    "    lip_landmarks = np.array([(int(landmark.x * width), int(landmark.y * height)) for landmark in landmarks])  # Normalize coordinates\n",
    "    if mask:  # If a mask is provided\n",
    "        lip_landmarks = lip_landmarks[mask]  # Apply the mask to filter specific landmarks\n",
    "    return lip_landmarks\n",
    "\n",
    "# Function to create a mask for lipstick application\n",
    "def lip_mask(src: np.ndarray, points: np.ndarray, color: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a mask for the lip area where the lipstick will be applied.\n",
    "    :param src: Input image.\n",
    "    :param points: Array of points representing the lip region.\n",
    "    :param color: Color of the lipstick in BGR format.\n",
    "    :return: A mask image with the lipstick applied to the lip region.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(src)  # Create a black mask (same size as the input image)\n",
    "    mask = cv2.fillPoly(mask, [points], color)  # Fill the lip area with the chosen color\n",
    "    mask = cv2.GaussianBlur(mask, (7, 7), 5)  # Apply Gaussian blur to smooth the edges of the mask\n",
    "    return mask\n",
    "\n",
    "# Function to apply lipstick to the image\n",
    "def apply_lipstick(src: np.ndarray, color: str = \"NO\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply lipstick to the image by overlaying a color mask on the lips.\n",
    "    :param src: Input image (BGR format).\n",
    "    :param color: Color of the lipstick.\n",
    "    :return: Image with lipstick applied.\n",
    "    \"\"\"\n",
    "    ret_landmarks = detect_landmarks(src)  # Detect face landmarks in the image\n",
    "    if ret_landmarks is None:  # If no landmarks are found, return the original image\n",
    "        return src\n",
    "\n",
    "    height, width, _ = src.shape  # Get image dimensions\n",
    "    feature_landmarks = landmarks(ret_landmarks, height, width, upper_lip + lower_lip)  # Extract lip landmarks\n",
    "\n",
    "    # Choose lipstick color based on input\n",
    "    if color == 'orange':\n",
    "        mask = lip_mask(src, feature_landmarks, [0, 143, 255])\n",
    "    elif color == 'purple':\n",
    "        mask = lip_mask(src, feature_landmarks, [255, 0, 0])\n",
    "    elif color == 'NO':\n",
    "        mask = lip_mask(src, feature_landmarks, [0, 0, 0])\n",
    "    elif color == 'pink':\n",
    "        mask = lip_mask(src, feature_landmarks, [153, 0, 157])\n",
    "    elif color == 'green':\n",
    "        mask = lip_mask(src, feature_landmarks, [0, 255, 0])\n",
    "    elif color == 'berry':\n",
    "        mask = lip_mask(src, feature_landmarks, [40, 0, 100])\n",
    "    elif color == 'caramel':\n",
    "        mask = lip_mask(src, feature_landmarks, [50, 70, 70])\n",
    "    elif color == 'yellow':\n",
    "        mask = lip_mask(src, feature_landmarks, [0, 255, 255])\n",
    "    elif color == 'aqua':\n",
    "        mask = lip_mask(src, feature_landmarks, [255, 255, 0])\n",
    "    elif color == 'peach':\n",
    "        mask = lip_mask(src, feature_landmarks, [35, 35, 139])\n",
    "    elif color == 'red':\n",
    "        mask = lip_mask(src, feature_landmarks, [2, 1, 159])\n",
    "\n",
    "    # Combine the original image and the mask\n",
    "    src1 = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)  # Convert original image to RGB\n",
    "    src1 = src\n",
    "    mask1 = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert mask to RGB\n",
    "    mask1 = mask\n",
    "    output = cv2.addWeighted(src1, 1.0, mask1, 0.4, 0.0)  # Blend the original and masked images\n",
    "    return output\n",
    "\n",
    "# Choose your settings here\n",
    "video_source: int = 0  # 0 for webcam, or you can specify a video file path (e.g., \"Videos/v1.mp4\")\n",
    "lip_color: str = 'red'  # Choose lip color: 'orange', 'purple', 'pink', 'green', etc.\n",
    "\n",
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()  # Read a frame from the video capture\n",
    "    if not ret:  # If reading the frame failed, break the loop\n",
    "        break\n",
    "\n",
    "    # Resize image for consistent display\n",
    "    img = cv2.resize(img, (700, 400))  # Resize the frame to a fixed size (700x400)\n",
    "    img = cv2.flip(img, 1)  # Flip the image horizontally for mirror effect\n",
    "\n",
    "    # Apply lipstick\n",
    "    output = apply_lipstick(img, lip_color)\n",
    "\n",
    "    # Show the output\n",
    "    cv2.imshow(\"Lipstick Application\", output)\n",
    "\n",
    "    # Exit if the user presses the 'Esc' key\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()  # Release the video capture object\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "class MakeupApplication:\n",
    "    def __init__(self, lip_color: str = \"NO\", eyeliner_color: list = [0, 0, 0], eyeliner_thickness: int = 2, debug: bool = False):\n",
    "        self.lip_color = lip_color\n",
    "        self.eyeliner_color = eyeliner_color\n",
    "        self.eyeliner_thickness = eyeliner_thickness\n",
    "        self.debug = debug\n",
    "\n",
    "        self.upper_lip = [61, 185, 40, 39, 37, 0, 267, 269, 270, 408, 415, 272, 271, 268, 12, 38, 41, 42, 191, 78, 76]\n",
    "        self.lower_lip = [61, 146, 91, 181, 84, 17, 314, 405, 320, 307, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        self.left_eye = [33, 246, 161, 160, 159, 158, 157, 173]\n",
    "        self.right_eye = [263, 466, 388, 387, 386, 385, 384, 398]\n",
    "\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    def detect_landmarks(self, src: np.ndarray) -> list | None:\n",
    "        with self.mp_face_mesh.FaceMesh() as face_mesh:\n",
    "            results = face_mesh.process(cv2.cvtColor(src, cv2.COLOR_BGR2RGB))\n",
    "            if results.multi_face_landmarks:\n",
    "                return results.multi_face_landmarks[0].landmark\n",
    "        return None\n",
    "\n",
    "    def extract_landmarks(self, landmarks: list, height: int, width: int, mask: list) -> np.ndarray:\n",
    "        return np.array([(int(landmark.x * width), int(landmark.y * height)) for landmark in landmarks])[mask]\n",
    "\n",
    "    def create_mask(self, src: np.ndarray, points: np.ndarray, color: list, thickness: int = -1) -> np.ndarray:\n",
    "        mask = np.zeros_like(src)\n",
    "        if thickness == -1:\n",
    "            mask = cv2.fillPoly(mask, [points], color)\n",
    "        else:\n",
    "            mask = cv2.polylines(mask, [points], isClosed=False, color=color, thickness=thickness)\n",
    "        return cv2.GaussianBlur(mask, (7, 7), 5)\n",
    "\n",
    "    def apply_makeup(self, src: np.ndarray) -> np.ndarray:\n",
    "        ret_landmarks = self.detect_landmarks(src)\n",
    "        if ret_landmarks is None:\n",
    "            return src\n",
    "\n",
    "        height, width, _ = src.shape\n",
    "\n",
    "        # Extract landmarks for lips and eyes\n",
    "        lip_landmarks = self.extract_landmarks(ret_landmarks, height, width, self.upper_lip + self.lower_lip)\n",
    "        left_eye_landmarks = self.extract_landmarks(ret_landmarks, height, width, self.left_eye)\n",
    "        right_eye_landmarks = self.extract_landmarks(ret_landmarks, height, width, self.right_eye)\n",
    "\n",
    "        # Create an overlay to blend the masks\n",
    "        overlay = src.copy()\n",
    "\n",
    "        # Apply lipstick\n",
    "        if self.lip_color != \"NO\":\n",
    "            lip_color_map = {\n",
    "                'orange': [0, 143, 255],\n",
    "                'purple': [255, 0, 0],\n",
    "                'pink': [153, 0, 157],\n",
    "                'green': [0, 255, 0],\n",
    "                'berry': [40, 0, 100],\n",
    "                'caramel': [50, 70, 70],\n",
    "                'yellow': [0, 255, 255],\n",
    "                'aqua': [255, 255, 0],\n",
    "                'peach': [35, 35, 139],\n",
    "                'red': [2, 1, 159]\n",
    "            }\n",
    "            lip_mask = self.create_mask(src, lip_landmarks, lip_color_map.get(self.lip_color, [0, 0, 0]))\n",
    "            overlay = cv2.addWeighted(overlay, 1.0, lip_mask, 0.4, 0.0)\n",
    "\n",
    "        # Apply eyeliner\n",
    "        mask_left_eye = self.create_mask(src, left_eye_landmarks, self.eyeliner_color, thickness=self.eyeliner_thickness)\n",
    "        mask_right_eye = self.create_mask(src, right_eye_landmarks, self.eyeliner_color, thickness=self.eyeliner_thickness)\n",
    "        overlay = cv2.addWeighted(overlay, 1.0, mask_left_eye, 0.6, 0.0)\n",
    "        overlay = cv2.addWeighted(overlay, 1.0, mask_right_eye, 0.6, 0.0)\n",
    "\n",
    "        # Debug Mode: Draw facial landmarks\n",
    "        if self.debug:\n",
    "            for landmark in ret_landmarks:\n",
    "                x, y = int(landmark.x * width), int(landmark.y * height)\n",
    "                cv2.circle(overlay, (x, y), 2, (0, 0, 255), -1)  # Red dots for debug\n",
    "\n",
    "        return overlay\n",
    "\n",
    "\n",
    "# Main script for video processing\n",
    "if __name__ == \"__main__\":\n",
    "    # Define user settings\n",
    "    video_source = 0  # 0 for webcam or path to video file\n",
    "    lip_color = 'red'  # Choose lipstick color: 'orange', 'purple', etc.\n",
    "    eyeliner_color = [0, 0, 0]  # Black eyeliner\n",
    "    debug_mode = True  # Enable debug mode to see landmarks\n",
    "\n",
    "    # Initialize MakeupApplication instance\n",
    "    makeup_app = MakeupApplication(lip_color=lip_color, eyeliner_color=eyeliner_color, debug=debug_mode)\n",
    "\n",
    "    # Start video capture\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img = cv2.resize(img, (700, 400))\n",
    "        img = cv2.flip(img, 1)\n",
    "\n",
    "        # Apply makeup\n",
    "        output = makeup_app.apply_makeup(img)\n",
    "\n",
    "        # Display the output\n",
    "        cv2.imshow(\"Makeup Application\", output)\n",
    "\n",
    "        # Break the loop if 'Esc' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
